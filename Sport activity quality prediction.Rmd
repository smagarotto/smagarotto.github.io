---
title: "Sport activity quality prediction"
author: "Stefano Magarotto"
date: "17 agosto 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive summary 

Fitness devices as Jawbone Up, Nike FuelBand and Fitbit allows people to collect
a large amount of data about personal activity.

People regularly quantify how much of a particular activity they do, but they 
rarely quantify how well they do it. 

In this project, our goal is to use data from accelerometers on the belt, 
forearm, arm, and dumbell of 6 participants to predict the manner in which 
they did the exercise. This is the "classe" variable in the training set. 
We may use any of the other variables to predict with. 

We have created a report describing how we built our model, how we used cross 
validation, what we think the expected out of sample error is, and why we made 
the choices we did. We will also use our prediction model to predict 
20 different test cases.

## Data

The training data for this project are available here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## Preliminary step

In order to obtain reproduceability, we set the seed:
```{r}
set.seed(7000)
```

load the required packages:
```{r}
library(caret)  # to install use: install.packages('caret', dependencies = TRUE)
                # so you install also package e1071
library(randomForest)
library(rpart) 
library(rpart.plot) 
library(RColorBrewer)
library(rattle)
```

get the data: 
```{r}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```

partition the training set in 2 data sets (60% myTraining, 40% myTest):
```{r}
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTest <- training[-inTrain, ]
dim(myTraining); dim(myTest)
```

clean the data:
1. cleaning NearZeroVariance variables
```{r}
myDataNZV <- nearZeroVar(myTraining, saveMetrics=TRUE)
myNZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[!myNZVvars]
```

2. remove first column because it can interfer with ML Algorithms
```{r}
myTraining <- myTraining[c(-1)]
dim(myTraining)
```

3. remove variables with excessive NAs (> 50%)
```{r}
myTrainingTemp <- myTraining 
for(i in 1:length(myTraining)) { 
        if( sum( is.na( myTraining[, i] ) ) / nrow(myTraining) >= .5 ) { 
        for(j in 1:length(myTrainingTemp)) {
            if( length( grep(names(myTraining[i]), names(myTrainingTemp)[j]) ) ==1)  { 
                myTrainingTemp <- myTrainingTemp[ , -j] 
            }   
        } 
    }
}
dim(myTrainingTemp)
myTraining <- myTrainingTemp
```

4. the same for myTest
```{r}
rem1 <- colnames(myTraining)
rem2 <- colnames(myTraining[, -58]) 
myTest <- myTest[rem1]
testing <- testing[rem2]
dim(myTest)
dim(testing)
```

5. coerce the data of the Test data set into the same type 
```{r}
for (i in 1:length(testing) ) {
        for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}
```

and check it worked
```{r}
testing <- rbind(myTraining[2, -58] , testing) 
testing <- testing[-1,]
```

## Prediction using Decision tree ML algorithm

Creating and viewing the Decision tree:
```{r}
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
```

and predicting:
```{r}
predictionsA1 <- predict(modFitA1, myTest, type = "class")
```

test results with confusion matrix:
```{r}
confusionMatrix(predictionsA1, myTest$classe)
```

## Prediction using Random forests ML algorithm

Creating the Random forest:
```{r}
modFitB1 <- randomForest(classe ~. , data=myTraining)
```

and predicting in-sample error:
```{r}
predictionsB1 <- predict(modFitB1, myTest, type = "class")
```

test results with confusion Matrix:
```{r}
confusionMatrix(predictionsB1, myTest$classe)
```

As we can see, Random forests gave better results.

## Generating the files requested

We use the Random forests that gave better results.
```{r}
predictionsB2 <- predict(modFitB1, testing, type = "class")
```

and generate the files with predictions requested:
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsB2)
```

